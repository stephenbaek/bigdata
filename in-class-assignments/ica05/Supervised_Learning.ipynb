{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< [Data Preprocessing and Visualization](../ica04/Data_Preprocessing_and_Visualization.ipynb) | Contents (TODO) |  [Distance and Similarity](../ica06/Distance_and_Similarity.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/stephenbaek/bigdata/blob/master/in-class-assignments/ica05/Supervised_Learning.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Supervised Learning for Big Data\n",
    "\n",
    "In this example, we will take a look at the issues regarding supervised learning in the context of big data. Especially, the computational speed is the major concern we will address here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, here's a simple trick you can use to measure the time elapsed for an operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.0006682872772217 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "time.sleep(3)  # an operation you want to evaluate\n",
    "elapsed_time = time.time() - start_time\n",
    "print('Elapsed time: {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this simple trick in hands, let's measure how long it takes to solve a linear system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us consider matrices $X\\in \\mathbb{R}^{N\\times d}$ and $Y \\in \\mathbb{R}^{N\\times 1}$ for some positive integers $N$ and $d < N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.82688573  0.47165244  1.08824753 ...  0.50151443  0.58691764\n",
      "   0.4984809 ]\n",
      " [ 0.68997807  0.27125976 -0.19720731 ...  0.26556187 -0.94286026\n",
      "   0.0847539 ]\n",
      " [-0.04441009  0.39262896  0.1909819  ... -0.06293562 -0.46122895\n",
      "   0.40619361]\n",
      " ...\n",
      " [ 1.76254267 -1.68874312  2.19269681 ...  0.72717735 -0.49292834\n",
      "  -0.07394764]\n",
      " [-1.65856344 -0.0805701  -0.28548451 ...  0.08856056 -0.11797907\n",
      "   0.41211544]\n",
      " [-0.4542066  -0.07892748 -0.304011   ... -1.15449534 -0.3829011\n",
      "  -0.92080214]]\n",
      "[[ 0.24855292]\n",
      " [ 0.08881808]\n",
      " [-0.61287652]\n",
      " ...\n",
      " [-0.11457917]\n",
      " [ 0.20423044]\n",
      " [ 0.79083479]]\n"
     ]
    }
   ],
   "source": [
    "N = 10000\n",
    "d = 500\n",
    "X = np.random.normal(loc=0, scale=1, size=[N, d])\n",
    "Y = np.random.normal(loc=0, scale=1, size=[N, 1])\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a linear system of equations $Y = XA$, the least square solution to this system is known as:\n",
    "\n",
    "\\begin{equation*}\n",
    "A = ((X^\\top X)^{-1}X^\\top)Y\n",
    "\\end{equation*}\n",
    "\n",
    "To compute this, a straightforward approach would be to (1) compute $X^\\top X$ first, (2) take the inverse $(X^\\top X)^{-1}$, (3) multiply $X^\\top$ to the result, and finally (4) multiply $Y$. The following is an analysis of how much of computational time is requred for each of the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for XTX: 0.06895947456359863 seconds\n",
      "Elapsed time for the inverse: 0.045972347259521484 seconds\n",
      "Elapsed time for the inverse times XT: 0.1908886432647705 seconds\n",
      "Elapsed time for the inverse times XT times Y: 0.004998683929443359 seconds\n",
      "Total: 0.310819149017334 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "XTX = np.matmul(X.T, X)\n",
    "XTX_elapsed_time = time.time() - start_time\n",
    "print('Elapsed time for XTX: {} seconds'.format(XTX_elapsed_time))\n",
    "\n",
    "start_time = time.time()\n",
    "inv = np.linalg.inv(XTX)\n",
    "inv_elapsed_time = time.time() - start_time\n",
    "print('Elapsed time for the inverse: {} seconds'.format(inv_elapsed_time))\n",
    "\n",
    "start_time = time.time()\n",
    "invXT = np.matmul(inv, X.T)\n",
    "invXT_elapsed_time = time.time() - start_time\n",
    "print('Elapsed time for the inverse times XT: {} seconds'.format(invXT_elapsed_time))\n",
    "\n",
    "start_time = time.time()\n",
    "A = np.matmul(invXT, Y)\n",
    "A_elapsed_time = time.time() - start_time\n",
    "print('Elapsed time for the inverse times XT times Y: {} seconds'.format(A_elapsed_time))\n",
    "\n",
    "print('Total: {} seconds'.format(XTX_elapsed_time + inv_elapsed_time + invXT_elapsed_time + A_elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, a simple trick can make a huge difference in computational time. Consider the same equation as above, but this time, let us switch the order of computation a little bit.\n",
    "\n",
    "\\begin{equation*}\n",
    "A = (X^\\top X)^{-1}(X^\\top Y)\n",
    "\\end{equation*}\n",
    "\n",
    "That is, this time, we are going to (1) compute $X^\\top X$ first, (2) take the inverse $(X^\\top X)^{-1}$, (3) compute $X^\\top Y$, and finally (4) multiply $(X^\\top X)^{-1}$ and $X^\\top Y$. Steps (1) and (2) are the same, but (3) and (4) is in different order. Let's take a look at how much time is required to compute the solution with this strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for XTX: 0.05097007751464844 seconds\n",
      "Elapsed time for the inverse: 0.02498602867126465 seconds\n",
      "Elapsed time for XTY: 0.00400233268737793 seconds\n",
      "Elapsed time for the inverse times XTY: 0.0 seconds\n",
      "Total: 0.07995843887329102 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "XTX = np.matmul(X.T, X)\n",
    "XTX_elapsed_time = time.time() - start_time\n",
    "print('Elapsed time for XTX: {} seconds'.format(XTX_elapsed_time))\n",
    "\n",
    "start_time = time.time()\n",
    "inv = np.linalg.inv(XTX)\n",
    "inv_elapsed_time = time.time() - start_time\n",
    "print('Elapsed time for the inverse: {} seconds'.format(inv_elapsed_time))\n",
    "\n",
    "start_time = time.time()\n",
    "XTY = np.matmul(X.T, Y)\n",
    "XTY_elapsed_time = time.time() - start_time\n",
    "print('Elapsed time for XTY: {} seconds'.format(XTY_elapsed_time))\n",
    "\n",
    "start_time = time.time()\n",
    "A = np.matmul(inv, XTY)\n",
    "A_elapsed_time = time.time() - start_time\n",
    "print('Elapsed time for the inverse times XTY: {} seconds'.format(A_elapsed_time))\n",
    "\n",
    "print('Total: {} seconds'.format(XTX_elapsed_time + inv_elapsed_time + XTY_elapsed_time + A_elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the significant reduction of computation time?\n",
    "\n",
    "### Assignment\n",
    "- Which step shows the greatest difference?\n",
    "- Why?\n",
    "- Fix $d = 500$ but try to increase $N$ from 10,000 to 20,000, 50,000, and 100,000. How does the computation time chanbge? Is there any trend?\n",
    "- Fix $N = 10000$ but increase $d$ from 500 to 1,000, 2,000, and 5,000. How does the computation time change? Is there any trend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Advanced Profiling\n",
    "\n",
    "Measuring times for running operations part by part is called profiling. Using `time` library is quite simple, but sometimes we may need some more advanced method. For example, you may have already noticed that the computation time of the same code can vary each time you run the code.\n",
    "\n",
    "One way of profiling your code is by using `%timeit` tag in front of the line you want to evaluate. For example:\n",
    "```python\n",
    "%timeit inv = np.linalg.inv(XTX)\n",
    "```\n",
    "runs `inv = np.linalg.inv(XTX)` multiple times and take the average and standard deviation of the computation time.\n",
    "\n",
    "Another way of doing it is by using `%prun` tag in front of the line. For instance:\n",
    "```python\n",
    "%prun inv = np.linalg.inv(XTX)\n",
    "```\n",
    "will provide more in-depth breakdown of the process. If you are, however, not so familiar with computer programing, `%prun` might be too much, as it gives too detailed information. In this case, you should just be fine with `%timeit` or the `time.time()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.4 ms ± 2.51 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit inv = np.linalg.inv(XTX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun inv = np.linalg.inv(XTX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn\n",
    "\n",
    "One of the reasons why Python is such popular in data science is due to free, open source libraries with pre-defined data analysis functions and algorithms. Among many others, `Scikit-learn` is perhaps the most popular Python library for beginners as they provide a wide variety of algorithm implementations as well as easy-to-follow tutorials. For more information, visit http://scikit-learn.org\n",
    "\n",
    "Scikit-learn can be installed on your computer by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\sbaek\\appdata\\local\\continuum\\anaconda3\\envs\\bigdata\\lib\\site-packages (0.21.3)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\sbaek\\appdata\\roaming\\python\\python36\\site-packages (from scikit-learn) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\sbaek\\appdata\\local\\continuum\\anaconda3\\envs\\bigdata\\lib\\site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\sbaek\\appdata\\local\\continuum\\anaconda3\\envs\\bigdata\\lib\\site-packages (from scikit-learn) (0.13.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it is installed, many machine learning modules including linear regression can be accessed like below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for Scikit-Learn: 0.4837191104888916 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "start_time = time.time()\n",
    "reg = LinearRegression(fit_intercept = False, n_jobs=1).fit(X, Y)\n",
    "sk_elapsed_time = time.time() - start_time\n",
    "print('Elapsed time for Scikit-Learn: {} seconds'.format(sk_elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Scikit-learn is not intended for production-level development. When you have a large data set, Scikit-learn can be extremely slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< [Data Preprocessing and Visualization](../ica04/Data_Preprocessing_and_Visualization.ipynb) | Contents (TODO) |  [Distance and Similarity](../ica06/Distance_and_Similarity.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/stephenbaek/bigdata/blob/master/in-class-assignments/ica05/Supervised_Learning.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python [conda env:bigdata]",
   "language": "python",
   "name": "conda-env-bigdata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
