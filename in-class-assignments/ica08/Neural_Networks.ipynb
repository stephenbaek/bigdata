{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< [Distance and Similarity](../ica07/Cluster_Analysis.ipynb) | Contents (TODO)\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/stephenbaek/bigdata/blob/master/in-class-assignments/ica08/Neural_Networks.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Artificial Neural Networks\n",
    "\n",
    "Artificial neural networks (ANN) have been around since 1950's but they gained popularity only very recently. ANNs are, in some sense, a stack of linear systems of equations, connected via a *computational graph*. The basic building block of ANNs is a neural network layer, representing a unit comprised of a linear system of equations. By connecting these layers, you can \"design\" an architecture of a neural network model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TensorFlow\n",
    "\n",
    "There are many software packages with pre-defined neural network functions. One of the most popular neural network packages is `TensorFlow`. TensorFlow was initially conceived as an internal project at Google, but it became an open source project from 2015. Since then, with the hype of deep learning research, TensorFlow has been vigorously used by research communities and industry, enabling the creation of a large number of project. In this lab, we will take a look at some of the basics of TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Installation\n",
    "(IF YOU'RE USING COLAB, YOU CAN SKIP THIS STEP)\n",
    "\n",
    "For the installation of TensorFlow, most of the cases, you can simply type `pip install tensorflow`. There is a GPU accelerated version of TensorFlow available, and can be installed via `pip install tensorflow-gpu`. For the GPU installation, you need CUDA and CuDNN installed on your computer. For the details, consult https://www.tensorflow.org/install. TensorFlow is a large library with many dependencies and subpackages, so the installation may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You DO NOT need to run this cell if you're running this notebook on Colab.\n",
    "# This take some time. Be patient...\n",
    "!pip install tensorflow\n",
    "#!pip install tensorflow-gpu  # to install GPU version, comment the above line and uncomment this line instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Getting Started\n",
    "TensorFlow can be imported by simply calling `import tensorflow as tf`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PLkhRZBT6d8b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To some extent, TensorFlow is similar to NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3\n",
    "b = 4\n",
    "c = tf.add(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the return type of the above code is `tf.Tensor`. Tensors are, mathematically, generalization of vectors and matrices to arbitrary dimensions. Many of the neural network computations are formulated based on tensors. To convert a tensor value to a numpy array, you can call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MNIST Hand-written Digit Recognition\n",
    "\n",
    "Modified National Institute of Science and Technology Hand-written Digit Data Set (MNIST) is one of the most popular \"hello world\" data set for data scientists. It is comprised of 60,000 training images of hand-written digits (0~9) and 15,000 test images on top of them. TensorFlow provides a set of codes to facilitate loading MNIST dats set as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P33jaV7c6mwa"
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train / 255.0   # normalize pixel value interval from 0~255 (common convention) to 0~1\n",
    "X_test = X_test / 255.0     # normalize pixel value interval from 0~255 (common convention) to 0~1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check if the data set is loaded correctly by displaying the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "q9lBC6sm-Ofy",
    "outputId": "b6f60871-7a1d-4ff3-e0b1-0365e7be26e6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.title(Y_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in TensorFlow, defining a neural network model is as simple as \"adding\" layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "i8ISfr8O64HE",
    "outputId": "36167f81-c560-4edb-db8f-5c64a24b6d7d"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add( tf.keras.layers.Flatten(input_shape=(28,28)) )\n",
    "model.add( tf.keras.layers.Dense(200, activation='sigmoid') )\n",
    "model.add( tf.keras.layers.Dense(10, activation='sigmoid') )\n",
    "model.summary()  # this prints out the summary of the model. (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once model has been defined, you need to compile and fit. `compile` is a process of specifing the training settings, such as the type of optimization algorithm, training objectives, metrics to display, etc. `fit` is a process where the actual tuning of the neural network parameters happen. For the scope of this course, here I show you a very basic set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "STDf5ITk8Hfg",
    "outputId": "db799867-8e2f-467a-de30-12b09a945067"
   },
   "outputs": [],
   "source": [
    "model.compile('SGD', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, Y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the training was successful, with a pretty good accuracy. Let's test if the model works fine. This can be done simply by passing an array of images to the function named `predict`. Note that, by convention, `predict` doesn't accept a single image, but an array only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "cptOFuma8Yqr",
    "outputId": "ce2e9ad7-b896-4210-cd5c-e0ed0b0b6656"
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test[0:1])   # predicted probabilities for each digit\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "plt.imshow(X_test[0], cmap='gray')\n",
    "plt.title(np.argmax(predicted))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the overall performace of the model on the entire test data set can be achieved by calling `evaluate` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7Upobj68WFS"
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< [Distance and Similarity](../ica07/Cluster_Analysis.ipynb) | Contents (TODO)\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/stephenbaek/bigdata/blob/master/in-class-assignments/ica08/Neural_Networks.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "colab": {
   "name": "BigData_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:bigdata]",
   "language": "python",
   "name": "conda-env-bigdata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
