{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< [Supervised Learning](../ica05/Supervised_Learning.ipynb) | Contents (TODO) |  [Cluster Analysis](../ica07/Cluster_Analysis.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/stephenbaek/bigdata/blob/master/in-class-assignments/ica06/Distance_and_Similarity.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance and Similarity\n",
    "\n",
    "## 1. The Iris Data Set\n",
    "\n",
    "The [Iris data set](https://archive.ics.uci.edu/ml/datasets/iris) is a popular \"hello world\" data set for data scientists. The data set contains three species of Iris flowers, including *Iris setosa*, *Iris versicolor*, and *Iris virginica* (see below).\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/220px-Kosaciec_szczecinkowaty_Iris_setosa.jpg><br>Iris setosa</td>\n",
    "        <td><img src=https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/220px-Iris_versicolor_3.jpg><br>Iris versicolor</td>\n",
    "        <td><img src=https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/220px-Iris_virginica.jpg><br>Iris virginica</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=3><center>The three species of Iris</center></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "These three spiecies are different in their sepal and petal dimensions. The data set contains four attributes, namely *sepal length*, *sepal width*, *petal length*, and *petal width*, for each flower.\n",
    "![](https://www.integratedots.com/wp-content/uploads/2019/06/iris_petal-sepal-e1560211020463.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Reading the Iris data set\n",
    "\n",
    "The Iris data set is available at the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Iris). There are several files in the repository, but all we need here is the data file https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data, which is *comma-separated*.\n",
    "\n",
    "In our previous session, we learned how to read a comma-separated file using pandas (see Section 4 of [ICA02 - How to Read and Represent Data]((../ica02/How_to_Read_and_Represent_Data.ipynb))). We first import numpy and pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment\n",
    "Write a code to read https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data file to a pandas DataFrame. Set `header=None` and `names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'iris_class']` to manually set the column names. Name your DataFrame `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our job easier in the future, we will convert the Sting data in `iris_class` column to ordinal variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ordinal = data.replace({'iris_class': {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}})\n",
    "data_ordinal.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once properly loaded, you should be able to run the following line to draw a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sepal_length.hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few other ways to visualize the data. For example, below is an example to visualize the sepal length distribution for different classes of irises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_type in data.iris_class.unique():\n",
    "    data.sepal_length.iloc[np.where(data.iris_class == class_type)].hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment\n",
    "- Write a code to draw the similar histogram plots for other attributes, i.e. sepal width, petal length, and petal width.\n",
    "- For each attribute, can you tell the difference between the three species? You can just \"eyeball\".\n",
    "- Based on your answer above, build a simple `if-else` logic to classify irises. Test your logic on the Iris data set. How accurate can you be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROVIDE YOUR ANSWERS HERE. IF NECESSARY, CREATE NEW CODE/TEXT CELLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could also visualize the data set in a 2-D scatter plot, each of the axes indicating one of those attributes. The type of the flower can be color-coded. We will use a library called `matplotlib` for visualization, which can be imported like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, simply `plt.scatter()` will do the job for drawing a scatter plot. If you are already familiar with MATLAB, `matplotlib` is a lot similar to MATLAB visualization functions. For more details, see: https://matplotlib.org/gallery/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_ordinal.sepal_length, data_ordinal.sepal_width, c=data_ordinal.iris_class)\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('sepal width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment\n",
    "\n",
    "- Write a code to draw the scatter plot for all the other combinations than 'sepal length' - 'sepal width'.\n",
    "- For each plot, can you draw a straight line separating the different species? (again, eyeballing) What is the slope and the intercept of the line you came up with, roughly?\n",
    "- Implement a linear classifier using the line equations you manually came up with. What is the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROVIDE YOUR ANSWERS HERE. IF NECESSARY, CREATE NEW CODE/TEXT CELLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. K-Nearest Neighbors\n",
    "\n",
    "K-nearest neighbors, or *KNN*, is one of the simplest machine learning (?) algorithm for supervised learning. There are many python libraries that provide nice, pre-defined implementations of KNN, but here, we will just implement everything from scratch on our own. Implementing a KNN is not actually difficult at all, and from the experience of implementing it, you will get to achieve some deeper insights on how things are working. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split\n",
    "\n",
    "In Iris data set, we have the total of 150 flower samples. We will randomly split these into two groups: group A with 120 flowers and group B with 30 flowers. We will \"train\" our KNN model based on the flowers in group A, and we will *pretend* the group B is a set of *queries* that we don't know the answer for. For example, assume you are building an app for telling the user which species of Iris it is, based on the sepal and petal shapes. Group A is the set of data that is already available to you (app developer) and Group B is the queue of queries that your users will randomly throw in. In data science, \"Group A\" the set of data you used for building a model is called *training set* and \"Group B\" the remainder of the data you left out is called *test set*. \n",
    "\n",
    "In Python world, there are a few pre-defined functions that are quite convenient for spliting train and test sets. Not that it is difficult to implement things from scratch, let's just take advantage of one of those functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data_ordinal, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to train KNN, we will convert `train` DataFrame to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_np = train.to_numpy()\n",
    "print(train_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first four columns are attributes we are going to use for making prediction (called *predictors*) and the last column is the species label we would like to predict (*output*). For simplicity, we will explicitly split those columns into `train_X` and `train_Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_np[:, 0:4]\n",
    "train_Y = train_np[:, 4]\n",
    "\n",
    "print(train_X)\n",
    "print(train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets simulate a user query from the test data set. In this example, we'll simply pick the first row of the test set and name it `query`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = test.iloc[0]\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, similarly, we'll convert it to a numpy array and \"pretend\" we don't know the species of this query by deleting the information. However, since we are going to check later whether or not the prediction is correct, we will save it somewhere for our record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query.to_numpy()\n",
    "ground_truth = query[4]\n",
    "query = np.delete(query, 4)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will find the which flower in the train set is the most similar to the query flower. To do this, we first compute the difference between each of the train data and the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.abs(train_X - query)  # absolute difference\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take the sum of differences across the different attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_diff = np.sum(diff, axis=-1)\n",
    "print(sum_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will find the k-nearest neighbors by picking the ones that have the smallest differences. To this, `np.argpartition()` can be extremely useful, especially when you have large data. The function is similar to `np.sort` in a sense that it tries to sort the input array in the ascending order. However, it sorts the array only up to the first k elements and simply ignores the remainder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "idx = np.argpartition(sum_diff, k)\n",
    "print(sum_diff[idx])  # Notice that only the first k elements have been sorted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the labels of the k-nearest neighbors are summarized as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "knn = train_Y[idx[:k]]\n",
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whichever label achieves the majority vote, it is going to be the predicted species of the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni, count = np.unique(knn, return_counts=True)\n",
    "print('Predicted Class: ', uni[np.argmax(count)])\n",
    "print('Ground Truth: ', ground_truth)             # compare with the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment\n",
    "\n",
    "- Implement a code to classify all the flowers in the test data set.\n",
    "- Compare the predicted result with the actual ground truth. What is the accuracy?\n",
    "- Plot the accuracy as you vary k=1, 2, 3, ..., 20. Does the accuracy changes along k? Is there any pattern you can observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< [Supervised Learning](../ica05/Supervised_Learning.ipynb) | Contents (TODO) |  [Cluster Analysis](../ica07/Cluster_Analysis.ipynb) >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/stephenbaek/bigdata/blob/master/in-class-assignments/ica06/Distance_and_Similarity.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python [conda env:bigdata]",
   "language": "python",
   "name": "conda-env-bigdata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
